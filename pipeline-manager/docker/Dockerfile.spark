FROM openjdk:11-slim

# Install required dependencies
RUN apt-get update && \
    apt-get install -y wget python3 python3-pip netcat procps && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Download and install Spark
RUN wget -q https://archive.apache.org/dist/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz && \
    tar -xzf spark-3.3.0-bin-hadoop3.tgz -C /opt && \
    rm spark-3.3.0-bin-hadoop3.tgz && \
    ln -s /opt/spark-3.3.0-bin-hadoop3 /opt/spark

# Set environment variables
ENV SPARK_HOME=/opt/spark
ENV PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
ENV PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.9.5-src.zip:$PYTHONPATH

# Create app directory
RUN mkdir -p /app/data /app/sql /app/jars

# Set working directory
WORKDIR /app

# Keep container running
CMD ["tail", "-f", "/dev/null"]